{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 TO 2023 US Congress members' stock transactions analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction and Posing Questions](#intro)\n",
    "- [Data Collection and Wrangling](#wrangle)\n",
    "- [Exploratory Data Analysis](#eda)\n",
    "   - [Statistics](#stats)\n",
    "   - [Visualizations](#visuals)\n",
    "- [Statistical Analysis](#statistical)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction and Posing Questions\n",
    "\n",
    "In this project, I will perform exploratory data analysis on the data provided by [House Stock Watcher](https://housestockwatcher.com/api) on the US Congress members' stock transactions for the years 2020, 2021, 2022, and 2023. The dataset includes various columns providing information on disclosure dates, transaction dates, asset details, transaction types, amounts, and other relevant attributes.\n",
    "I seek to uncover patterns, trends, and potential conflicts of interest within the data. As a result, I have developed thought-provoking questions that can guide my analysis and uncover meaningful insights:\n",
    "\n",
    "1. What are the primary motivations driving Congress members' stock transactions?\n",
    "   - How do demographic factors such as party affiliation, and state influence trading activities?\n",
    "   - Are there noticeable patterns in trading behavior based on transaction types such as purchases or sales?\n",
    "   - Can we identify any correlation such as transaction amount and party affiliations?  \n",
    "2. Are there observable trends in the frequency and volumes of stock transactions over multiple years?\n",
    "   - Do certain years exhibit higher trading activities among Congress members, and if so, what factors might contribute to these fluctuations?\n",
    "   - How does transaction volume vary across different sectors and industries, are there sectors that Congress members show a particular interest in?\n",
    "   - Can we identify any anomalies or spikes in trading activities that warrant further investigation? \n",
    "3. Can we analyze the performance of Congress members' stock portfolios and identify any notable trends?\n",
    "   - How do capital gain from stock transactions vary across different party affiliations?\n",
    "   - Are there sectors that Congress members consistently realize higher capital gains, and what factors might explain these trends?\n",
    "4. How can we cross-analyze trends between data dimensions to uncover deeper insights?\n",
    "   - Are there correlations between transaction frequencies and demographic factors such as party affiliations?\n",
    "   - How do sector-specific trends in stock transactions correlate with party affiliations?\n",
    "   - Can we identify any systematic biases or patterns in trading activities that warrant further investigations?\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"wrangle\"></a>\n",
    "## Data Collection and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data utilized in this project is sourced from [House Stock Watcher](https://housestockwatcher.com), offering comprehensive stock transaction information of US Congress members spanning the years 2020 to 2023. Accessible via [House Stock Watcher API](https://house-stock-watcher-data.s3-us-west-2.amazonaws.com/data/all_transactions.json), this data is conveniently available in JSON format, facilitating integration and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Style\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(1572223 bytes read, 7105118 more expected)', IncompleteRead(1572223 bytes read, 7105118 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/urllib3/response.py:737\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/urllib3/response.py:883\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_content_length\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Content-Length are caught.\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_bytes_read, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining)\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read1 \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    885\u001b[0m     (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m    886\u001b[0m ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;66;03m# `http.client.HTTPResponse`, so we close it here.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# See https://github.com/python/cpython/issues/113199\u001b[39;00m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(1572223 bytes read, 7105118 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/urllib3/response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/urllib3/response.py:963\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m<\u001b[39m amt \u001b[38;5;129;01mand\u001b[39;00m data:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# it one byte at a time\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m     decoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(data, decode_content, flush_decoder)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/urllib3/response.py:861\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 861\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_catcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfp_closed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/urllib3/response.py:761\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         arg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection broken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProtocolError(arg, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPException, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(1572223 bytes read, 7105118 more expected)', IncompleteRead(1572223 bytes read, 7105118 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Get the data from the API and change it into Pandas DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m api_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://house-stock-watcher-data.s3-us-west-2.amazonaws.com/data/all_transactions.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/requests/models.py:818\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentDecodingError(e)\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(1572223 bytes read, 7105118 more expected)', IncompleteRead(1572223 bytes read, 7105118 more expected))"
     ]
    }
   ],
   "source": [
    "## Get the data from the API and change it into Pandas DataFrame\n",
    "api_url = \"https://house-stock-watcher-data.s3-us-west-2.amazonaws.com/data/all_transactions.json\"\n",
    "response = requests.get(api_url)\n",
    "data = response.json()\n",
    "df = pd.DataFrame(data)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data loaded, it's observable from the above printout that the column formats are different even where the information is the same e.g. the date columns; `disclosure_date` and `transaction_date`. We will trim and clean the data to make things as simple as possible when we get to the actual exploration. Cleaning the data makes sure that the data formats are consistent while trimming focuses only on the part of the data we are interested in to make the exploration easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns relevant to the analysis\n",
    "columns_to_drop = [\"ticker\",\"asset_description\", \"ptr_link\", \"district\"]\n",
    "stocks = df.drop(columns = columns_to_drop)\n",
    "# Identify the indexes of the rows containing the problematic dates and drop them\n",
    "index1 = stocks[stocks[\"transaction_date\"] == \"0009-06-09\"].index\n",
    "index2 = stocks[stocks[\"transaction_date\"] == \"0022-11-23\"].index\n",
    "index3 = stocks[stocks[\"transaction_date\"] == \"0021-08-02\"].index\n",
    "index4 = stocks[stocks[\"transaction_date\"] == \"0222-11-22\"].index\n",
    "index5 = stocks[stocks[\"transaction_date\"] == \"0023-01-11\"].index\n",
    "index6 = stocks[stocks[\"transaction_date\"] == \"0021-06-22\"].index\n",
    "index7 = stocks[stocks[\"transaction_date\"] == \"0201-06-22\"].index\n",
    "index8 = stocks[stocks[\"transaction_date\"] == \"0222-11-02\"].index\n",
    "problematic_indexes = list(index1) + list(index2) + list(index3) + list(index4) + list(index5) + list(index6) + list(index7) + list(index8)\n",
    "stocks.drop(problematic_indexes, inplace = True)\n",
    "# Replace the incorrect dates with correct ones using .loc\n",
    "stocks.loc[stocks[\"transaction_date\"] == \"20222-08-09\", \"transaction_date\"] = \"2022-08-09\"\n",
    "stocks.loc[stocks[\"transaction_date\"] == \"20222-07-18\", \"transaction_date\"] = \"2022-07-18\"\n",
    "stocks.loc[stocks[\"transaction_date\"] == \"20222-11-16\", \"transaction_date\"] = \"2022-11-16\"\n",
    "stocks.loc[stocks[\"transaction_date\"] == \"20221-11-18\", \"transaction_date\"] = \"2021-11-18\"\n",
    "# Convert date columns to DateTime data type with specified formats\n",
    "stocks[\"disclosure_date\"] = pd.to_datetime(stocks[\"disclosure_date\"], format = \"%m/%d/%Y\")\n",
    "stocks[\"transaction_date\"] = pd.to_datetime(stocks[\"transaction_date\"], format = \"%Y-%m-%d\")\n",
    "stocks.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eda\"></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Now that we have the data wrangled, we're ready to start exploring the data. In this section, I will dive deep into our dataset to uncover patterns, trends, anomalies, and relationships that will provide valuable insights into our data. \n",
    "To begin the exploration, I will compute some descriptive statistics from the data, and then move into visualizations.\n",
    "\n",
    "<a id=\"stats\"></a>\n",
    "### Statistics\n",
    "\n",
    "First, let's compute some basic statistics from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptive_statistics(df):\n",
    "    total_transactions = len(df)\n",
    "\n",
    "    highest_transaction_rep = df['representative'].value_counts().idxmax()\n",
    "    highest_transaction_count = df['representative'].value_counts().max()\n",
    "\n",
    "    highest_transaction_party = df['party'].value_counts().idxmax()\n",
    "    highest_transaction_party_count = df['party'].value_counts().max()\n",
    "\n",
    "    most_common_amount = df['amount'].mode()[0]\n",
    "    most_common_amount_count = df['amount'].value_counts().max()\n",
    "    \n",
    "    most_common_sector = df['sector'].mode()[0]\n",
    "    most_common_industry = df['industry'].mode()[0]\n",
    "    most_common_transaction_type = df['type'].mode()[0]\n",
    "    most_common_owner = df['owner'].mode()[0]\n",
    "    most_common_state = df['state'].mode()[0]\n",
    "\n",
    "    # transactions_by_year = df['disclosure_year'].value_counts().to_dict()\n",
    "\n",
    "    party_groups = stocks.groupby(\"party\")\n",
    "    party_stats = party_groups[\"amount\"].describe()\n",
    "\n",
    "    print(\"Findings:\")\n",
    "    print(Fore.GREEN + f\"Total number of transactions: \" + Fore.RED + f\"{total_transactions}\")\n",
    "    print(Fore.GREEN + f\"Representative with the highest number of transactions: \" + Fore.RED +\n",
    "          f\"{highest_transaction_rep} ({highest_transaction_count} transactions)\")\n",
    "    print(Fore.GREEN + f\"Party with the highest number of transactions: \" + Fore.RED +\n",
    "          f\"{highest_transaction_party} ({highest_transaction_party_count} transactions)\")\n",
    "    print(Fore.GREEN + f\"Most common transaction amount: \" + Fore.RED +\n",
    "          f\"{most_common_amount} ({most_common_amount_count} transactions)\")\n",
    "    print(Fore.GREEN + f\"Sector with the most transactions: \" + Fore.RED + f\"{most_common_sector}\")\n",
    "    print(Fore.GREEN + f\"Industry with the most transactions: \" + Fore.RED + f\"{most_common_industry}\")\n",
    "    print(Fore.GREEN + f\"Most common transaction type: \" + Fore.RED + f\"{most_common_transaction_type}\")\n",
    "    print(Fore.GREEN + f\"Owner accounts that transacted most: \" + Fore.RED + f\"{most_common_owner}\")\n",
    "    print(Fore.GREEN + f\"State with most transactions: \" + Fore.RED + f\"{most_common_state}\")\n",
    "    # print(Fore.GREEN + \"\\nNumber of Stock Transactions by Year:\")\n",
    "    # for year, count in transactions_by_year.items():\n",
    "    #     print(Fore.RED + f\"{year}: {count}\")\n",
    "\n",
    "    print(Fore.GREEN + f\"Analyze transactions descriptive statistics for each party:\" + \"\\n \" + Fore.RED + f\"{party_stats}\")\n",
    "\n",
    "compute_descriptive_statistics(stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visuals\"></a>\n",
    "### Visualizations\n",
    "\n",
    "I will further explore the US Congress members' stock data using visualizations created with Matplotlib and Seaborn libraries. I aim to gain deeper insights into the stock transaction and understand the patterns and trends from the period 2020 to 2023.\n",
    "\n",
    "**1. Distribution of Transaction Amounts**\n",
    "\n",
    "Let's start by visualizing the distribution of transaction amounts to understand the range and frequency of transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.histplot(stocks['amount'], kde=True)\n",
    "plt.title('Distribution of Transaction Amounts', color = 'royalblue', weight = 'bold')\n",
    "plt.xlabel('Amount ($)', color = 'lime')\n",
    "plt.ylabel('Frequency', color = 'lime')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Histogram above shows that most of the US Congress members' stock transaction amounts were in the range of $1000-$15000. This aligns with our calculation above where we found that 12079 transactions out of 17162 were in this range.\n",
    "The above plot has a kernel density estimate(KDE) which provides a smoothened representation of the underlying distribution of the transaction amounts. The data shape is right-skewed, indicating that most US Congress members' transactions have lower amounts, with a few transactions having higher amounts.\n",
    "\n",
    "**2. Distribution of transaction amounts by Party Affiliations**\n",
    "\n",
    "Let's now visualize the distribution of transaction amounts by party affiliations to see if there are any differences in trading behaviours among different political parties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.histplot(data=stocks, x='amount', hue='party', kde=True, multiple='stack')\n",
    "plt.title('Distribution of Transaction Amounts by Party Affiliations', color='royalblue', weight='bold')\n",
    "plt.xlabel('Amount ($)', color='lime')\n",
    "plt.ylabel('Frequency', color='lime')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that most transactions were carried out by Democrats, which aligns with our calculations from above where the Democrats had 10500 transactions. However, as the transaction amount increases, we see slightly more transactions by the Republicans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Distribution of transactions across different sectors**\n",
    "\n",
    "Here, I will explore the distribution of transactions across different sectors to identify which sectors are most frequently involved in stock transactions by Congress members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.countplot(data=stocks, y='sector')\n",
    "plt.title('Distribution of transactions across different sectors', color='royalblue', weight='bold')\n",
    "plt.xlabel('Number of Transactions', color='lime')\n",
    "plt.ylabel('Sector', color='lime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can see that the Technology sector had the most stock transactions by the Congress members. Other sectors like Health Care, Finance, Consumer Services, and Energy had higher transactions while sectors like Telecommunications, Basic Materials, and Consumer Staples had the least transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Distribution of transactions by year grouped by Party affiliations**\n",
    "\n",
    "I will further explore the data to observe the variation in  transaction activity among different political parties over the years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.countplot(data=stocks, x='disclosure_year', hue='party')\n",
    "plt.title('Distribution of Transactions by Year Grouped by Party Affiliations', color='royalblue', weight='bold')\n",
    "plt.xlabel('Year', color='lime')\n",
    "plt.ylabel('Number of Transactions', color='lime')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By examining the heights of the bars, we can see that the Democrats had more transactions across the years followed by the Republicans. Generally, the number of transactions decreased across the years with some parties such as the Jackson and Libertarian having little to no transactions across the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Distributions of Transactions and Dislosures.**\n",
    "\n",
    "Here, we utilize a time-series plot to examine the counts of transactions and disclosures recorded on each respective date, providing insights into the frequency and distribution of these events in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_by_transaction_date = stocks.groupby('transaction_date').size().reset_index(name='transaction_count')\n",
    "disclosures_by_disclosure_date = stocks.groupby('disclosure_date').size().reset_index(name='disclosure_count')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(transactions_by_transaction_date['transaction_date'], transactions_by_transaction_date['transaction_count'], color='royalblue', label='Transactions')\n",
    "plt.plot(disclosures_by_disclosure_date['disclosure_date'], disclosures_by_disclosure_date['disclosure_count'], color='orange', label='Disclosures')\n",
    "plt.title('Number of Transactions and Disclosures Over Time', color='royalblue', weight='bold')\n",
    "plt.xlabel('Date', color='lime')\n",
    "plt.ylabel('Count', color='lime')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the above visualization, we can see that the years 2012 to 2019 recorded some transactions with no disclosure until the year 2020 onwards, and the years 2019 to 2023 had the most transactions and disclosures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"#statistical\"></a>\n",
    "## Statistical Analysis\n",
    "\n",
    "In this section, I will delve into a comprehensive statistical analysis of the Congress members' stock data to uncover meaningful insights, patterns, and relationships within the data.\n",
    "\n",
    "To further understand the data, I will describe the number of stock transactions per year and determine which party, industry, sector, amount, owner type, state, type, and if there were capital gains in each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_by_year = stocks['disclosure_year'].value_counts().to_dict()\n",
    "print(Fore.GREEN + \"\\nNumber of Stock Transactions by Year:\")\n",
    "for year, count in transactions_by_year.items():\n",
    "    print(Fore.RED + f\"{year}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_by_year_party = stocks.groupby(['disclosure_year', 'party']).size().unstack(fill_value=0)\n",
    "print(Fore.GREEN + \"Number of Stock Transactions by Year and Party:\")\n",
    "print(Fore.RED + f\"{transactions_by_year_party}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industries_by_year = stocks.groupby(['disclosure_year', 'industry']).size().reset_index(name='count')\n",
    "industries_by_year = industries_by_year.loc[industries_by_year.groupby('disclosure_year')['count'].idxmax()]\n",
    "\n",
    "print(Fore.GREEN + \"Industries Traded Most Each Year:\")\n",
    "print(Fore.RED + f\"{industries_by_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_by_year = stocks.groupby(['disclosure_year', 'sector']).size().reset_index(name='count')\n",
    "sectors_by_year = sectors_by_year.loc[sectors_by_year.groupby('disclosure_year')['count'].idxmax()]\n",
    "\n",
    "print(Fore.GREEN + \"Sectors Traded Most Each Year:\")\n",
    "print(Fore.RED + f\"{sectors_by_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_by_year = stocks.groupby(['disclosure_year', 'state']).size().reset_index(name='count')\n",
    "states_by_year = states_by_year.loc[states_by_year.groupby('disclosure_year')['count'].idxmax()]\n",
    "\n",
    "print(Fore.GREEN + \"States Traded Most Each Year:\")\n",
    "print(Fore.RED + f\"{states_by_year}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (Python 3.11.8)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
